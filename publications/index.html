<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Projects | Gio (Jiwoong) Choi</title> <meta name="author" content="Gio (Jiwoong) Choi"> <meta name="description" content="For more details, please click on the ABS and Code sections. My full name is Jiwoong Choi, but I go by Gio."> <meta name="keywords" content="jiwoong choi, Gio Choi, data science, computational social science, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://gio-choi.github.io/publications/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Gio (Jiwoong) </span>Choi</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Projects<span class="sr-only">(current)</span></a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Projects</h1> <p class="post-description">For more details, please click on the ABS and Code sections. My full name is Jiwoong Choi, but I go by Gio.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-6 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/would_cite_should_cite-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/would_cite_should_cite-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/would_cite_should_cite-1400.webp"></source> <img src="/assets/img/publication_preview/would_cite_should_cite.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="would_cite_should_cite.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="choi2025clinicaltrialscitationbias" class="col-sm-6"> <div class="title">What Would Clinical Trials Cite — and What Should They Cite? Citation Bias and the p-value Heap in Clinical Research</div> <div class="author"> <em>Jiwoong Choi</em> </div> <div class="periodical"> <em>Working Paper (MA Thesis), Manuscript Ready</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Citations in clinical trial registrations do more than acknowledge prior work; they define the evidentiary context in which regulators and clinicians interpret results. I use this role to construct a trial-level \emphCitation Bias Index (CBI) that measures how far a trial’s background citations at registration depart from the set of studies it ought to cite given pre-results information. Using 547,866 interventional trials on ClinicalTrials.gov linked to 39 million PubMed papers, I apply language model embeddings to identify content-relevant prior trials and systematic reviews (a “should-cite” set) and a matrix factorization model of the trial–paper citation network to estimate citation probabilities over candidate prior papers for the focal trial (a “would-cite” distribution). CBI is the symmetric Kullback–Leibler divergence between these distributions. Citation bias is lowest for trials that later report highly significant results (p ≤ 0.01) and spikes sharply for borderline findings just below p = 0.05, creating a pronounced p-value heap. In regressions with registration-year and condition fixed effects, higher CBI predicts a significantly greater probability that the trial’s outcome falls in the narrow borderline band (0.045 &lt; p ≤ 0.05).</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-6 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/ES_2024_v2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/ES_2024_v2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/ES_2024_v2-1400.webp"></source> <img src="/assets/img/publication_preview/ES_2024_v2.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="ES_2024_v2.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="choi2025bready4ai" class="col-sm-6"> <div class="title">BReady4AI: A Global AI Innovation Index</div> <div class="author"> </div> <div class="periodical"> <em>Working Project, World Bank</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>We construct an annual, country-level AI innovation index organized around three pillars: Production of AI, Consumption of AI, and Participation in AI. Using indicators built from publications, patents, grants, collaboration networks, and demographic diversity, we score and rank countries on their capacity for frontier AI innovation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-6 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/white_v2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/white_v2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/white_v2-1400.webp"></source> <img src="/assets/img/publication_preview/white_v2.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="white_v2.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bao2025languagemodelssurfaceunwritten" class="col-sm-6"> <div class="title">Language Models Surface the Unwritten Code of Science and Society</div> <div class="author"> Honglin Bao, Siyang Wu<sup>*</sup>, Jiwoong Choi<sup>*</sup>, Yingrong Mao<sup>*</sup>, and James A. Evans</div> <div class="periodical"> <em>Submitted to ACL 2026</em>, Dec 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2505.18942" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>This paper calls on the research community not only to investigate how human biases are inherited by large language models (LLMs) but also to explore how these biases in LLMs can be leveraged to make society’s "unwritten code" - such as implicit stereotypes and heuristics - visible and accessible for critique. We introduce a conceptual framework through a case study in science: uncovering hidden rules in peer review - the factors that reviewers care about but rarely state explicitly due to normative scientific expectations. The idea of the framework is to push LLMs to speak out their heuristics through generating self-consistent hypotheses - why one paper appeared stronger in reviewer scoring - among paired papers submitted to 45 computer science conferences, while iteratively searching deeper hypotheses from remaining pairs where existing hypotheses cannot explain. We observed that LLMs’ normative priors about the internal characteristics of good science extracted from their self-talk, e.g. theoretical rigor, were systematically updated toward posteriors that emphasize storytelling about external connections, such as how the work is positioned and connected within and across literatures. This shift reveals the primacy of scientific myths about intrinsic properties driving scientific excellence rather than extrinsic contextualization and storytelling that influence conceptions of relevance and significance. Human reviewers tend to explicitly reward aspects that moderately align with LLMs’ normative priors (correlation = 0.49) but avoid articulating contextualization and storytelling posteriors in their review comments (correlation = -0.14), despite giving implicit reward to them with positive scores. We discuss the broad applicability of the framework, leveraging LLMs as diagnostic tools to surface the tacit codes underlying human society, enabling more precisely targeted responsible AI.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-6 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/tsne-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/tsne-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/tsne-1400.webp"></source> <img src="/assets/img/publication_preview/tsne.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="tsne.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ACM_CI" class="col-sm-6"> <div class="title">Academic Simulacra: Forcasting Research Ideas through Multi-Agent LLM Simulations</div> <div class="author"> <em>Jiwoong Choi</em>, Yingrong Mao, Donghyun Kang, and James Evans</div> <div class="periodical"> <em>Poster Presentation at ACM Collective Intelligence 2025; Submitted to The Web Conference (WWW 2026)</em>, Aug 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ci.acm.org/2025/wp-content/uploads/Academic_Simulacra_Final.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p><i> Keywords: Multi-Agent Simulation, Simulated Scholarship, Large Language Models </i> <br> We introduce a multi-agent simulation framework for forecasting research ideas using "scholar agents" powered by large language models (LLMs). We instantiate approximately 2,686 scholar agents based on their publication histories prior to 2024 and simulate discussions to collectively generate key research ideas for 1,400 papers targeting seven major computer science conferences in 2024. We then evaluate the proximity of these generated ideas by comparing their semantic embeddings with those of the actual target papers written by the corresponding researchers. Our results suggest that LLM-based multi-agent simulations yield substantially higher similarity scores with real publications than two baselines: (1) the average pairwise similarity among papers within the same 2024 conference, and (2) a random set of past papers from the same conference. This demonstrates the predictive capacity of our scholar agent framework. We then further analyze how diversity in ethnic composition and institutional affiliations may correlate with the predictability of research, or inversely, the degree of surprise relative to the past. Our preliminary analysis suggests that the least predictable and thus most surprising research ideas emerge from teams affiliated with Chinese institutions but not composed of ethnically Chinese authors. These findings offer promising initial evidence that simulating knowledge-driven scholar agents can anticipate directions of scientific discovery and help explain the influence of social and institutional factors on innovation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-6 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/recursive-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/recursive-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/recursive-1400.webp"></source> <img src="/assets/img/publication_preview/recursive.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="recursive.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ICSSI" class="col-sm-6"> <div class="title">Automating Scholarly Judgment</div> <div class="author"> <em>Jiwoong Choi</em>, Siyang Wu, Yingrong Mao, and Honglin Bao</div> <div class="periodical"> <em>(Oral Presentation) International Conference on the Science of Science and Innovation (ICSSI)</em>, Jun 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Automating_Scholarly_Judgm.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p><i> Keywords: Automated Hypothesis Generation, Scientific Evaluation, Large Language Models </i> <br> What constitutes good science remains a longstanding question in both philosophy and practice. Traditional peer review, for instance, has been critiqued for subjectivity, inconsistency, and potential bias. Recent advances in large language models (LLMs) offer a novel opportunity to re-examine this question at scale. Here, we analyze a dataset of approximately 27K papers submitted to 45 computer science conferences, paired on review scores to create clear distinctions in perceived quality. Rather than manually defining the criteria of “good” science, we task LLMs with iteratively proposing, testing, and refining hypotheses that explain why one paper might be judged as stronger than another. This yields a final pool of 20 orthogonal hypotheses with high coverage of pairs. Throughout this abductive reasoning process, the LLM’s initial “normative” prior beliefs (e.g., a good paper has high novelty) are updated into a posterior that reflects more professional-science criteria (e.g., a good paper tells a good story). LLMs could serve as powerful tools for uncovering latent patterns in how experts judge scientific work. Nevertheless, challenges remain. Interpretability is a critical bottleneck: while the iterative process yields human-understandable hypotheses, it relies on opaque LLM reasoning under the hood. In addition, substantial progress is still needed in guiding LLMs and humans toward a clearer understanding of what constitutes truly valuable science.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-6 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/msci_logo2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/msci_logo2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/msci_logo2-1400.webp"></source> <img src="/assets/img/publication_preview/msci_logo2.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="msci_logo2.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="MSCI" class="col-sm-6"> <div class="title">Korea Discount and Corporate Governance</div> <div class="author"> SK Kim, Ye Jun Kim, and <em>Jiwoong Choi</em> </div> <div class="periodical"> <em>Morgan Stanley Capital International (MSCI Inc.</em>, Jun 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>This paper examines the "Board and Ownership and Control" Key Issue within the MSCI ESG Ratings Corporate Governance Theme, with a focus on board independence and adherence to the one-share-one-vote (OSOV) principle. Our analysis reveals significant governance challenges among Korean companies. Notably, less than half of the directors on Korean company boards are independent, a figure significantly lower than the global average of 66%. Additionally, 82% of Korean companies were flagged for Related Party Transactions (RPT), with smaller firms exhibiting lower board independence. Furthermore, Korean companies that deviated from the OSOV principle demonstrated weaker financial performance, with both return-on-equity (ROE) and price-to-book ratio (PBR) falling below the market average. These findings underscore the need for enhanced governance practices within Korean corporations to align more closely with global standards.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-6 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/ASEAN_thumbnail-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/ASEAN_thumbnail-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/ASEAN_thumbnail-1400.webp"></source> <img src="/assets/img/publication_preview/ASEAN_thumbnail.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="ASEAN_thumbnail.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="UN" class="col-sm-6"> <div class="title">ASEAN Gender Outlook 2024</div> <div class="author"> Statistics-Jiwoong Choi</div> <div class="periodical"> <em>UN General Assembly (UNGA)</em>, Jun 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/ASEAN-gender-outlook_2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>- Despite high primary and lower secondary education completion rates in ASEAN, only 64 percent of students complete upper secondary education, with boys, particularly in rural areas, being more likely to drop out due to economic barriers and opportunity costs. While girls tend to stay in school longer, challenges such as inadequate access to employment opportunities, poor educational infrastructure, and disparities between urban and rural areas persist, highlighting the need for increased investments in education across the region. <br> - Adolescent birth rates in South-East Asia have decreased from 41 to 35 per 1,000 between 2015 and 2024, with factors such as delayed marriage, access to contraceptives, and education contributing to this decline. However, disparities in education infrastructure, particularly in rural areas, remain a challenge, with limited access to basic facilities like sanitation and water, which increases the likelihood of teenage pregnancy and school dropout among rural girls. <br> - Despite South-East Asia being one of the world’s safest regions with a homicide rate of 1.8 per 100,000 people, a growing sense of insecurity, particularly among women, has emerged due to factors like COVID-19, economic disruptions, and crime, highlighting the need for enhanced law enforcement and inclusive security approaches. <br> - Over the past decade, official development assistance (ODA) for gender equality in the ASEAN region has increased significantly, with 47% of all ODA in 2022 supporting gender-focused initiatives, though investments directly targeting gender equality have declined, highlighting the need for continued and expanded funding to sustain progress in areas like women’s participation, violence reduction, and the gender-environment nexus.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-6 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/SLAM.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/SLAM.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/SLAM.gif-1400.webp"></source> <img src="/assets/img/publication_preview/SLAM.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="SLAM.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="irc" class="col-sm-6"> <div class="title">Outdoor visual SLAM and Path Planning for Mobile-Robot</div> <div class="author"> Seongil Heo, Jueun Mun, <em>Jiwoong Choi</em>, Jiwon Park, and Eric T. Matson</div> <div class="periodical"> <em>IEEE International Conference on Robotic Computing (IRC)</em>, Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/Gio-Choi/Autonomous_Vehicle_Purdue_University" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>This paper proposes a robust visual SLAM and a path planning algorithm for autonomous vehicles in the outdoor environment. The consideration of the outdoor characteristics was essential in both SLAM and path planning processes. This study can be used when it is necessary to know the exact appearance of the environment due to the impossibility of observing the environment through a satellite map, e.g., inside a forest. The visual SLAM system was developed using GPS data in consideration of the deterioration of camera recognition performance outdoors. The GPS data was inserted into every multi-thread of visual SLAM, which are Camera Tracking, Local Mapping, and Loop Closing. It enhanced the accuracy of the map and saved computational power by preventing useless calculations. In the path planning part, our method divided the path based on the stability of the roads. When determining the optimal path, the stability of the road and the driving time were considered, and the weight was assigned based on the GPS data.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-6 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/mirae_asset-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/mirae_asset-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/mirae_asset-1400.webp"></source> <img src="/assets/img/publication_preview/mirae_asset.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="mirae_asset.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Mirae" class="col-sm-6"> <div class="title">Stock Investment Opinion Sentimental Analysis</div> <div class="author"> </div> <div class="periodical"> <em>Mirae Asset Big Data Hackathon</em>, Nov 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Mirae_ppt.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/orgs/sw-membership/repositories" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>- Collected text data from YouTube videos, YouTube comments, News, and Bank Reports by STT, OCR, and Crawling methods. <br> - Fine-tuned Google’s ELECTRA model which is a GAN-based transformer model by PyTorch. <br> - Conducted a Sentimental Analysis and made a prototype service. <br> - Gave a presentation on behalf of our team and finally achieved 4th place out of 1,000.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>